{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62b00a3-7185-42a8-9800-836954dbc89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from typing import List, Optional\n",
    "\n",
    "from datasets import load_dataset\n",
    "import json\n",
    "import zlib\n",
    "import pickle\n",
    "import base64\n",
    "from enum import Enum\n",
    "from datetime import datetime\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "class Platform(Enum):\n",
    "    LEETCODE = \"leetcode\"\n",
    "    CODEFORCES = \"codeforces\"\n",
    "    ATCODER = \"atcoder\"\n",
    "\n",
    "\n",
    "class Difficulty(Enum):\n",
    "    EASY = \"easy\"\n",
    "    MEDIUM = \"medium\"\n",
    "    HARD = \"hard\"\n",
    "\n",
    "\n",
    "class TestType(Enum):\n",
    "    STDIN = \"stdin\"\n",
    "    FUNCTIONAL = \"functional\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Test:\n",
    "    input: str\n",
    "    output: str\n",
    "    testtype: TestType\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.testtype = TestType(self.testtype)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CodeGenerationProblem:\n",
    "    question_title: str\n",
    "    question_content: str\n",
    "    platform: Platform\n",
    "    question_id: str\n",
    "    contest_id: str\n",
    "    contest_date: datetime\n",
    "    starter_code: str\n",
    "    difficulty: Difficulty\n",
    "    public_test_cases: list[Test]\n",
    "    private_test_cases: list[Test]\n",
    "    metadata: dict\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.platform = Platform(self.platform)\n",
    "        self.difficulty = Difficulty(self.difficulty)\n",
    "        self.contest_date = datetime.fromisoformat(self.contest_date)\n",
    "\n",
    "        self.public_test_cases = json.loads(self.public_test_cases)  # type: ignore\n",
    "        self.public_test_cases = [Test(**t) for t in self.public_test_cases]\n",
    "\n",
    "        try:\n",
    "            self.private_test_cases = json.loads(self.private_test_cases)  # type: ignore\n",
    "        except:\n",
    "            self.private_test_cases = json.loads(\n",
    "                pickle.loads(\n",
    "                    zlib.decompress(\n",
    "                        base64.b64decode(self.private_test_cases.encode(\"utf-8\"))  # type: ignore\n",
    "                    )\n",
    "                )\n",
    "            )  # type: ignore\n",
    "        self.private_test_cases = [Test(**t) for t in self.private_test_cases]\n",
    "\n",
    "        self.metadata = json.loads(self.metadata)  # type: ignore\n",
    "\n",
    "    def insert_output(self, output_list: list[str], code_list: list[str]) -> dict:\n",
    "        return {\n",
    "            \"question_title\": self.question_title,\n",
    "            \"question_content\": self.question_content,\n",
    "            \"platform\": self.platform.value,\n",
    "            \"question_id\": self.question_id,\n",
    "            \"contest_id\": self.contest_id,\n",
    "            \"contest_date\": self.contest_date.isoformat(),\n",
    "            \"starter_code\": self.starter_code,\n",
    "            \"difficulty\": self.difficulty.value,\n",
    "            \"output_list\": output_list,\n",
    "            \"code_list\": code_list,\n",
    "        }\n",
    "\n",
    "    def insert_output_evaluation(\n",
    "        self,\n",
    "        output_list: list[str],\n",
    "        code_list: list[str],\n",
    "        graded_list: list[bool],\n",
    "        **kwargs,\n",
    "    ) -> dict:\n",
    "        output = self.insert_output(output_list, code_list)\n",
    "        output[\"graded_list\"] = graded_list\n",
    "        output[\"pass@1\"] = graded_list.count(True) / len(graded_list)\n",
    "        for k, v in kwargs.items():\n",
    "            output[k] = v\n",
    "        return output\n",
    "\n",
    "    def get_evaluation_sample(self):\n",
    "        return {\n",
    "            \"input_output\": json.dumps(\n",
    "                {\n",
    "                    \"inputs\": [\n",
    "                        t.input\n",
    "                        for t in self.public_test_cases + self.private_test_cases\n",
    "                    ],\n",
    "                    \"outputs\": [\n",
    "                        t.output\n",
    "                        for t in self.public_test_cases + self.private_test_cases\n",
    "                    ],\n",
    "                    \"fn_name\": self.metadata.get(\"func_name\", None),\n",
    "                }\n",
    "            ),\n",
    "        }\n",
    "\n",
    "def load_code_generation_dataset(\n",
    "    release_version: str = \"release_v2\",\n",
    "    start_date: Optional[str] = None,\n",
    "    end_date: Optional[str] = None,\n",
    ") -> List[CodeGenerationProblem]:\n",
    "    \"\"\"\n",
    "    Fetches the 'test' split of livecodebench/code_generation_lite at the given\n",
    "    release tag, wraps each record in CodeGenerationProblem, and optionally\n",
    "    filters by contest_date between start_date and end_date (YYYY-MM-DD).\n",
    "    \"\"\"\n",
    "    raw_ds = load_dataset(\n",
    "        \"livecodebench/code_generation_lite\",\n",
    "        split=\"test\",\n",
    "        version_tag=release_version,\n",
    "        trust_remote_code=True,\n",
    "    )\n",
    "    problems = [CodeGenerationProblem(**p) for p in raw_ds]\n",
    "\n",
    "    if start_date:\n",
    "        p0 = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "        problems = [p for p in problems if p.contest_date >= p0]\n",
    "\n",
    "    if end_date:\n",
    "        p1 = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "        problems = [p for p in problems if p.contest_date <= p1]\n",
    "\n",
    "    print(f\"Loaded {len(problems)} problems (release={release_version})\")\n",
    "    return problems\n",
    "\n",
    "import re\n",
    "\n",
    "def simplify_inputs(text: str) -> str:\n",
    "    # this will catch “Input: words = […]” (or any var name) and collapse it to “Input: […]”\n",
    "    return re.sub(\n",
    "        r'Input:\\s*\\w+\\s*=\\s*(\\[[^\\]]*\\])',\n",
    "        r'Input: \\1',\n",
    "        text\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import re, ast\n",
    "\n",
    "# ---------- transform_input_block  ----------\n",
    "def transform_input_block(spec: str) -> str:\n",
    "    \"\"\"\n",
    "    将 narrative 里的 “key = value” / 独立 value 依出现顺序改写成 stdin：\n",
    "        • 2-D 数组 [[...], ...]   → 每行 “x y z”\n",
    "        • 1-D 数组 [...]          → 一行 “x y z”\n",
    "        • 标量 / 字符串           → 一行\n",
    "    **注意**：只输出 value；键名 (apple, capacity…) 永远不写入结果。\n",
    "    \"\"\"\n",
    "    import ast, re\n",
    "\n",
    "    events: list[tuple[int, str, object]] = []\n",
    "\n",
    "    token_re = re.compile(\n",
    "        r\"\"\"\n",
    "        (?P<kv_array>      \\b\\w+\\s*=\\s*\\[[^\\[\\]]*(?:\\[[^\\[\\]]*\\][^\\[\\]]*)*\\])   # key = [ ... ]\n",
    "      | (?P<kv_scalar>     \\b\\w+\\s*=\\s*(?: \"(?:\\\\.|[^\"\\\\])*\" | '(?:\\\\.|[^'\\\\])*' | True | False | -?\\d+(?:\\.\\d+)? | \\w+))\n",
    "      | (?P<array>         \\[[^\\[\\]]*(?:\\[[^\\[\\]]*\\][^\\[\\]]*)*\\])               # standalone [ ... ]\n",
    "      | (?P<scalar>        \"(?:\\\\.|[^\"\\\\])*\" | '(?:\\\\.|[^'\\\\])*' | True | False | -?\\d+(?:\\.\\d+)? | \\w+)\n",
    "        \"\"\",\n",
    "        re.X,\n",
    "    )\n",
    "\n",
    "    for m in token_re.finditer(spec):\n",
    "        span_start = m.start()\n",
    "\n",
    "        # 1) key = [array]\n",
    "        if m.group(\"kv_array\"):\n",
    "            lit = m.group(\"kv_array\").split(\"=\", 1)[1].lstrip()\n",
    "            arr = ast.literal_eval(lit)\n",
    "            events.append((span_start, \"array\", arr))\n",
    "            continue\n",
    "\n",
    "        # 2) key = scalar\n",
    "        if m.group(\"kv_scalar\"):\n",
    "            val = m.group(\"kv_scalar\").split(\"=\", 1)[1].lstrip()\n",
    "            if val[0] in \"\\\"'\":   # strip quotes\n",
    "                val = val[1:-1]\n",
    "            events.append((span_start, \"scalar\", val))\n",
    "            continue\n",
    "\n",
    "        # 3) standalone array\n",
    "        if m.group(\"array\"):\n",
    "            arr = ast.literal_eval(m.group(\"array\"))\n",
    "            events.append((span_start, \"array\", arr))\n",
    "            continue\n",
    "\n",
    "        # 4) standalone scalar\n",
    "        if m.group(\"scalar\"):\n",
    "            tok = m.group(\"scalar\")\n",
    "            if tok[0] in \"\\\"'\":\n",
    "                tok = tok[1:-1]\n",
    "            events.append((span_start, \"scalar\", tok))\n",
    "\n",
    "    # ---------- 2) 依原文顺序输出 ----------------------------------------------\n",
    "    events.sort(key=lambda e: e[0])\n",
    "    lines: list[str] = []\n",
    "    for _, kind, val in events:\n",
    "        if kind == \"scalar\":\n",
    "            lines.append(str(val))\n",
    "        else:                               # array\n",
    "            if isinstance(val, list) and val and all(isinstance(r, list) for r in val):\n",
    "                lines.extend(\" \".join(map(str, r)) for r in val)\n",
    "            else:\n",
    "                lines.append(\" \".join(map(str, val)))\n",
    "\n",
    "    return \"\\n\".join(lines) + \"\\n\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def transform_spec_block(spec: str) -> str:\n",
    "    \"\"\"\n",
    "    Turn specs like\n",
    "        \"ss = 3, work = ['a','b'], kk = True\"\n",
    "    or\n",
    "        \"[0,1,1,0,2]\"\n",
    "    into:\n",
    "        3\n",
    "        a b\n",
    "        True\n",
    "\n",
    "    or\n",
    "\n",
    "        0 1 1 0 2\n",
    "    (with a trailing newline).\n",
    "    \"\"\"\n",
    "    events = []\n",
    "    masked = spec\n",
    "\n",
    "    # 1) bracket-match first [[…]] as before\n",
    "    start = spec.find('[[')\n",
    "    if start != -1:\n",
    "        depth = 0\n",
    "        end = None\n",
    "        for i, ch in enumerate(spec[start:], start):\n",
    "            if ch == '[':   depth += 1\n",
    "            elif ch == ']':\n",
    "                depth -= 1\n",
    "                if depth == 0:\n",
    "                    end = i\n",
    "                    break\n",
    "        if end is not None:\n",
    "            literal = spec[start:end+1]\n",
    "            try:\n",
    "                arr2d = ast.literal_eval(literal)\n",
    "            except:\n",
    "                arr2d = []\n",
    "            events.append((start, 'array2d', arr2d))\n",
    "            masked = masked[:start] + ' '*(end+1-start) + masked[end+1:]\n",
    "    else:\n",
    "        # 2) fallback to first 1D […] literal\n",
    "        m1 = re.search(r'\\[[^\\[\\]]*\\]', spec)\n",
    "        if m1:\n",
    "            lit = m1.group(0)\n",
    "            try:\n",
    "                raw = ast.literal_eval(lit)\n",
    "                parts = [str(x) for x in raw]\n",
    "            except:\n",
    "                parts = [x.strip() for x in lit.strip('[]').split(',') if x.strip()]\n",
    "            events.append((m1.start(), 'array1d', parts))\n",
    "            masked = masked[:m1.start()] + ' '*(m1.end()-m1.start()) + masked[m1.end():]\n",
    "\n",
    "    # 3) capture any key=value scalars\n",
    "    for m in re.finditer(\n",
    "        r'(\\w+)\\s*=\\s*'\n",
    "        r'( \"(?:\\\\.|[^\"\\\\])*\" | \\'(?:\\\\.|[^\\'\\\\])*\\' | [^\\s,]+ )',\n",
    "        masked,\n",
    "        flags=re.VERBOSE\n",
    "    ):\n",
    "        val = m.group(2)\n",
    "        if (val.startswith('\"') and val.endswith('\"')) or (val.startswith(\"'\") and val.endswith(\"'\")):\n",
    "            val = val[1:-1]\n",
    "        events.append((m.start(), 'scalar', val))\n",
    "\n",
    "    # 4) sort & 5) emit\n",
    "    events.sort(key=lambda e: e[0])\n",
    "    out = []\n",
    "    for _, typ, data in events:\n",
    "        if typ == 'scalar':\n",
    "            out.append(data)\n",
    "        elif typ == 'array1d':\n",
    "            out.append(\" \".join(data))\n",
    "        else:  # array2d\n",
    "            for row in data:\n",
    "                out.append(\" \".join(map(str, row)))\n",
    "    return \"\\n\".join(out) + \"\\n\"\n",
    "\n",
    "\n",
    "def find_matching(s: str, start: int) -> int:\n",
    "    \"\"\"Given s[start] == '[', return the index of its matching ']'.\"\"\"\n",
    "    depth = 0\n",
    "    for i in range(start, len(s)):\n",
    "        if s[i] == '[':\n",
    "            depth += 1\n",
    "        elif s[i] == ']':\n",
    "            depth -= 1\n",
    "            if depth == 0:\n",
    "                return i\n",
    "    return None\n",
    "\n",
    "# ---------- 1. replace_output_block ----------\n",
    "def replace_output_block(text: str) -> str:\n",
    "    \"\"\"\n",
    "    把   Output: …            → Output:\\n<多行展开格式>\\n\n",
    "    兼容：标量、1D/2D 列表；标量若带引号一并剥掉。\n",
    "    \"\"\"\n",
    "    def strip_quotes(tok: str) -> str:\n",
    "        return tok[1:-1] if len(tok) >= 2 and tok[0] in \"\\\"'\" and tok[-1] == tok[0] else tok\n",
    "\n",
    "    out, last = [], 0\n",
    "    for m in re.finditer(r'Output\\s*:', text):\n",
    "        out.append(text[last:m.end()])   # “…Output:”\n",
    "        i = m.end()\n",
    "        while i < len(text) and text[i].isspace():\n",
    "            out.append(text[i]); i += 1\n",
    "        if i >= len(text): break\n",
    "\n",
    "        if text[i] == '[':                              # —— 列表输出 ——\n",
    "            start, end = i, find_matching(text, i)\n",
    "            literal = text[start:end+1] if end else \"[]\"\n",
    "            try:\n",
    "                arr = ast.literal_eval(literal)\n",
    "            except Exception:\n",
    "                arr = []\n",
    "            lines = ([\" \".join(map(str, r)) for r in arr]\n",
    "                     if arr and all(isinstance(r, list) for r in arr)\n",
    "                     else [\" \".join(map(str, arr))])\n",
    "            out.append(\"\\n\" + \"\\n\".join(lines) + \"\\n\")\n",
    "            last = (end or i) + 1\n",
    "\n",
    "        else:                                           # —— 标量输出 ——\n",
    "            m2 = re.match(r'(-?\\d+|True|False|\"(?:\\\\.|[^\"\\\\])*\"|\\'(?:\\\\.|[^\\'\\\\])*\\')',\n",
    "                           text[i:])\n",
    "            if m2:\n",
    "                token = strip_quotes(m2.group(0))\n",
    "                out.append(f\"\\n{token}\\n\")\n",
    "                last = i + len(m2.group(0))\n",
    "            else:\n",
    "                last = i\n",
    "    out.append(text[last:])\n",
    "    return \"\".join(out)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import re, ast\n",
    "\n",
    "def find_matching2(s: str, start: int) -> int:\n",
    "    \"\"\"\n",
    "    Given s[start] == '[', find the matching closing ']' index\n",
    "    by counting bracket depth.\n",
    "    \"\"\"\n",
    "    depth = 0\n",
    "    for i in range(start, len(s)):\n",
    "        if s[i] == '[':\n",
    "            depth += 1\n",
    "        elif s[i] == ']':\n",
    "            depth -= 1\n",
    "            if depth == 0:\n",
    "                return i\n",
    "    return None\n",
    "\n",
    "def transform_tokens(s: str) -> str:\n",
    "    \"\"\"\n",
    "    Emits one line per token in the order they appear:\n",
    "      - 2D array [[...],...] → each row “x y z”\n",
    "      - 1D array  [a,b,c]     → “a b c”\n",
    "      - Quoted    \"foo\"       → foo\n",
    "      - Bare      bar         → bar\n",
    "    \"\"\"\n",
    "    events = []\n",
    "    masked = s\n",
    "\n",
    "    # 1) Extract the first nested 2D array [[…]]:\n",
    "    start2 = s.find('[[')\n",
    "    if start2 != -1:\n",
    "        end2 = find_matching2(s, start2)\n",
    "        if end2 is not None:\n",
    "            arr_lit = s[start2:end2+1]\n",
    "            try:\n",
    "                arr2d = ast.literal_eval(arr_lit)\n",
    "            except:\n",
    "                arr2d = []\n",
    "            # record its position & data\n",
    "            events.append((start2, 'array2d', arr2d))\n",
    "            # mask it out so we don't re-match inside\n",
    "            masked = masked[:start2] + ' '*(end2+1 - start2) + masked[end2+1:]\n",
    "\n",
    "    # 2) Tokenize what's left into 1D arrays, quoted strings, or bare tokens:\n",
    "    token_re = re.compile(r'\\[[^\\]]*\\]|\"(?:\\\\.|[^\"\\\\])*\"|\\'(?:\\\\.|[^\\'\\\\])*\\'|\\S+')\n",
    "    for m in token_re.finditer(masked):\n",
    "        tok = m.group(0)\n",
    "        pos = m.start()\n",
    "\n",
    "        if tok.startswith('[') and tok.endswith(']'):\n",
    "            # 1D array\n",
    "            try:\n",
    "                raw = ast.literal_eval(tok)\n",
    "                parts = [str(x) for x in raw]\n",
    "            except:\n",
    "                parts = [x.strip() for x in tok.strip('[]').split(',') if x.strip()]\n",
    "            events.append((pos, 'array1d', parts))\n",
    "\n",
    "        elif (tok.startswith('\"') and tok.endswith('\"')) or (tok.startswith(\"'\") and tok.endswith(\"'\")):\n",
    "            # quoted string\n",
    "            events.append((pos, 'scalar', tok[1:-1]))\n",
    "\n",
    "        else:\n",
    "            # bare token (number, boolean, identifier…)\n",
    "            events.append((pos, 'scalar', tok))\n",
    "\n",
    "    # 3) Sort by the original position\n",
    "    events.sort(key=lambda e: e[0])\n",
    "\n",
    "    # 4) Emit each line in order\n",
    "    out = []\n",
    "    for _, typ, data in events:\n",
    "        if typ == 'scalar':\n",
    "            out.append(str(data))\n",
    "        elif typ == 'array1d':\n",
    "            out.append(\" \".join(data))\n",
    "        else:  # array2d\n",
    "            for row in data:\n",
    "                out.append(\" \".join(map(str, row)))\n",
    "\n",
    "    return \"\\n\".join(out) + \"\\n\"\n",
    "\n",
    "def replace_input_block(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Finds the \"Input: ... [possibly huge spec] ...\"\n",
    "    and replaces just that part with\n",
    "      Input:\n",
    "      <multi-line transformed block>\n",
    "    preserving the rest of 'text'.\n",
    "    \"\"\"\n",
    "    def _repl(m):\n",
    "        # m.group(1) is \"Input:\" prefix\n",
    "        # m.group(2) is the spec to transform\n",
    "        prefix = m.group(1)\n",
    "        spec    = m.group(2)\n",
    "        transformed = transform_input_block(spec)\n",
    "        # note: we leave the trailing newline on transformed,\n",
    "        # and continue after the spec (Output: or end-of-string)\n",
    "        return f\"{prefix}\\n{transformed}\"\n",
    "    \n",
    "    # we look for Input: ... (non-greedy) up to Output: or end\n",
    "    pattern = re.compile(\n",
    "        r'(Input\\s*:\\s*)(.*?)(?=\\s*(?:Output\\s*:|$))',\n",
    "        flags=re.IGNORECASE|re.DOTALL\n",
    "    )\n",
    "    return pattern.sub(_repl, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d1bceb-b6ec-4033-a2b7-258238deceac",
   "metadata": {},
   "outputs": [],
   "source": [
    "release_tag = \"release_v2\"       # e.g. \"release_v1\", \"release_v2\", etc.\n",
    "start = None                     # e.g. \"2023-01-01\" or None\n",
    "end = None                       # e.g. \"2023-12-31\" or None\n",
    "# ————————————————\n",
    "\n",
    "\n",
    "problems = load_code_generation_dataset(\n",
    "    release_version=release_tag,\n",
    "    start_date=start,\n",
    "    end_date=end,\n",
    ")\n",
    "\n",
    "if not problems:\n",
    "    print(\"No problems found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f39133c-db73-48bd-b443-32230840255d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = []\n",
    "i = 0\n",
    "\n",
    "\n",
    "def modify(c):\n",
    "    c = c.strip()\n",
    "\n",
    "    c = c.replace(\"\\\\n\", \"\\n\")\n",
    "\n",
    "    if not c.endswith(\"\\n\"):\n",
    "        c += \"\\n\"\n",
    "    \n",
    "    return c\n",
    "\n",
    "num_function = 0\n",
    "for problem in problems:\n",
    "    #if i % 10 == 0:\n",
    "    #    print(i)\n",
    "    data_i = {}\n",
    "    data_i[\"dataset\"] = \"LiveCodeBench\"\n",
    "    if problem.private_test_cases[0].testtype.value == \"functional\":\n",
    "        data_i[\"question\"] = replace_output_block(replace_input_block(problem.question_content.strip()))\n",
    "        data_i[\"test_input\"] = [modify(transform_tokens(t.input))  for t in problem.private_test_cases]\n",
    "        data_i[\"test_output\"] = [modify(transform_tokens(t.output))  for t in problem.private_test_cases]\n",
    "        data_i[\"example_input\"] = [modify(transform_tokens(t.input))  for t in problem.public_test_cases]\n",
    "        data_i[\"example_output\"] = [modify(transform_tokens(t.output))  for t in problem.public_test_cases]\n",
    "        num_function += 1\n",
    "    else:\n",
    "        data_i[\"question\"] = problem.question_content.strip()\n",
    "        data_i[\"test_input\"] = [modify(t.input)  for t in problem.private_test_cases]\n",
    "        data_i[\"test_output\"] = [modify(t.output)  for t in problem.private_test_cases]\n",
    "        data_i[\"example_input\"] = [modify(t.input)  for t in problem.public_test_cases]\n",
    "        data_i[\"example_output\"] = [modify(t.output)  for t in problem.public_test_cases]\n",
    "    data_i[\"solutions\"] = None\n",
    "    data_i[\"difficulty\"] = problem.difficulty.value\n",
    "    \n",
    "    data_i[\"task_id\"] = i\n",
    "    data_i[\"test_time_limit\"] = 8\n",
    "    data_i[\"exe_method\"] = \"stdin\"\n",
    "    i += 1\n",
    "    new_data.append(data_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f9e4f7-a273-4e27-a5ce-3b03bd45831c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"LiveCodeBench.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(new_data, f, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef44efe-26c4-4543-a887-c365e99291fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CURE",
   "language": "python",
   "name": "cure"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
